{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"generate_dataset_1.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"QvmWuw8qjYaX"},"outputs":[],"source":["from google.colab import drive\n","import os\n","import json\n","import numpy as np # Для работы с данными \n","import matplotlib.pyplot as plt # Для вывода графиков\n","\n","%matplotlib inline\n","\n","from tensorflow.keras import utils # Для работы с категориальными данными\n","from tensorflow.keras.models import Sequential # Полносвязная модель\n","from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Flatten, Activation # Слои для сети\n","from tensorflow.keras.preprocessing.text import Tokenizer # Методы для работы с текстами\n","from tensorflow.keras.preprocessing.sequence import pad_sequences # Метод для работы с последовательностями"]},{"cell_type":"code","source":["drive.mount('drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"--wWf8dDj4Gu","executionInfo":{"status":"ok","timestamp":1639498773650,"user_tz":-180,"elapsed":3490,"user":{"displayName":"Игорь Молчанов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYdLWH6k0781lHDY2fOHciQCMySUAFsaUrdGZFxQ=s64","userId":"05120680139566347989"}},"outputId":"ac860ea5-21f8-4af6-905d-587f081ed556"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at drive\n"]}]},{"cell_type":"code","source":["dataset_dir = '/content/drive/MyDrive/Future_Foundation/Up_Great_Сколково/Satellites'"],"metadata":{"id":"NE5t4uWtuIIR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Все тексты true и false объединены в два больших текста;\n","Датасет - список из двух элементов-строк"],"metadata":{"id":"yEqPLQ4RWbUE"}},{"cell_type":"code","source":["# создаём два списка, в пустые элементы которых будем добавлять тексты\n","# в первом элементе будет храниться текст с ответом False, во втором - True\n","trainText = ['', '']\n","testText = ['', '']\n","\n","# открываем файл с id эссе и ответами\n","with open('/content/drive/MyDrive/Future_Foundation/Up_Great_Сколково/Satellites/train/train_standart.json', 'r') as f_list:\n","  data = json.load(f_list)\n","\n","  # проходимся по каждому \"блоку\" с эссе\n","  for i in range(len(data)):\n","    elem = data[i]\n","\n","    # ввыделяем на тестовую выборку 10 процентов\n","    if i < len(data)//10:\n","\n","      # с помощью форматированной строки открываем файл в названии которого id, который указан в блоке\n","      with open(f'/content/drive/MyDrive/Future_Foundation/Up_Great_Сколково/Satellites/train/essays/{elem[\"id\"]}.json', 'r') as essay:\n","        file = json.load(essay)\n","        text = file['text']\n","        \n","        if elem['answer'] == False:\n","          testText[0] += text\n","          testText[0] += ' '\n","        else:\n","          testText[1] += text\n","          testText[1] += ' '\n","      continue\n","\n","    with open(f'/content/drive/MyDrive/Future_Foundation/Up_Great_Сколково/Satellites/train/essays/{elem[\"id\"]}.json', 'r') as essay:\n","      file = json.load(essay)\n","      text = file['text']\n","      if elem['answer'] == False:\n","        trainText[0] += text\n","        trainText[0] += ' '\n","      else:\n","        trainText[1] += text\n","        trainText[1] += ' '"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":270},"id":"UdQUzDqvvtat","executionInfo":{"status":"error","timestamp":1639498780212,"user_tz":-180,"elapsed":338,"user":{"displayName":"Игорь Молчанов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYdLWH6k0781lHDY2fOHciQCMySUAFsaUrdGZFxQ=s64","userId":"05120680139566347989"}},"outputId":"dbda315d-a548-4e59-efa6-f4b7def7ff43"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-f0cce548efe3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# открываем файл с id эссе и ответами\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Future_Foundation/Up_Great_Сколково/Satellites/train/train_standart.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Future_Foundation/Up_Great_Сколково/Satellites/train/train_standart.json'"]}]},{"cell_type":"code","source":["numWords = 20000 # Количество слов/индексов, которое мы будем учитывать при обучении\n","\n","# настраиваем токенайзер, все слова приводятся в нижний регистр, специальные символы опускаются\n","tokenizer = Tokenizer(num_words=numWords,\n","                      filters='!\"#$%&()*+,-–—./…:;<=>?@[\\\\]^_`{|}~«»\\t\\n\\xa0\\ufeff',\n","                      lower=True,\n","                      split=' ',\n","                      oov_token='unknown',\n","                      char_level=False)\n","\n","tokenizer.fit_on_texts(trainText) # словарь частотности\n","items = list(tokenizer.word_index.items()) # индексы слов"],"metadata":{"id":"p36nUSOjV5cH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Самые часто встречающиеся слова:\")\n","print(items[:10])\n","print()\n","print(\"Самые редко встречающиеся слова:\")\n","print(items[-10:])\n","print()\n","print(\"Размер словаря:\", len(items))"],"metadata":{"id":"Y2OOrGFIYPLY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Преобразовываем текст в последовательность индексов согласно частотному словарю\n","trainWordIndexes = tokenizer.texts_to_sequences(trainText)\n","testWordIndexes = tokenizer.texts_to_sequences(testText)"],"metadata":{"id":"xD1bhptVYRik"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# классы, на которые делятся тексты\n","labels = ['false', 'true']\n","labelsNum = len(labels)"],"metadata":{"id":"zOtbDxD0Ymg3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Статистика по обучающим текстам:\")\n","\n","symbolsTrainText = 0\n","wordsTrainText = 0\n","\n","for i in range(labelsNum):\n","  print(labels[i], \" \"*(10-len(labels[i])), len(trainText[i]), \"символов, \", len(trainWordIndexes[i]), \"слов\")\n","  symbolsTrainText += len(trainText[i])\n","  wordsTrainText += len(trainWordIndexes[i])\n","\n","print('----')\n","print(\"В сумме \", symbolsTrainText, \" символов, \", wordsTrainText, \" слов \\n\")\n","print()\n","print(\"Статистика по тестовым текстам:\")\n","\n","symbolsTestText = 0\n","wordsTestText = 0\n","\n","for i in range(labelsNum):\n","  print(labels[i], ' '*(10-len(labels[i])), len(testText[i]), \"символов, \", len(testWordIndexes[i]), \"слов\")\n","  symbolsTestText += len(testText[i])\n","  wordsTestText += len(testWordIndexes[i])\n","print('----')\n","print(\"В сумме \", symbolsTestText, \" символов, \", wordsTestText, \" слов\")"],"metadata":{"id":"z3wSB0q4YfYl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def getSetFromIndexes(wordIndexes, xLen, step):\n","  xText = []\n","  wordsLen = len(wordIndexes) # Считаем количество слов\n","  index = 0 # Задаем начальный индекс \n","\n","  while (index + xLen <= wordsLen): # Идём по всей длине вектора индексов\n","    xText.append(wordIndexes[index:index+xLen]) # \"Откусываем\" векторы длины xLen\n","    index += step # Смещаемся вперёд на step\n","    \n","  return xText\n","\n","\n","# Формирование обучающей и проверочной выборки для каждого класса\n","# wordIndexes - массив индексов\n","# xLen - размер окна\n","# step - шаг окна\n","\n","def createSetsMultiClasses(wordIndexes, xLen, step): # Функция принимает последовательность индексов, размер окна, шаг окна\n","  nClasses = len(wordIndexes) # Количество классов\n","  classesXSamples = []        # Здесь будет список размером \"кол-во классов*кол-во окон в тексте*длину окна\"\n","  for wI in wordIndexes:      # Для каждого текста выборки из последовательности индексов\n","    classesXSamples.append(getSetFromIndexes(wI, xLen, step))\n","\n","  # Формируем один общий xSamples\n","  xSamples = []\n","  ySamples = []\n","  \n","  for t in range(nClasses):\n","    xT = classesXSamples[t]\n","    for i in range(len(xT)): # Перебираем каждое окно определенного класса\n","      xSamples.append(xT[i]) # Добавляем в общий список выборки\n","      ySamples.append(utils.to_categorical(t, nClasses)) # Добавляем соответствующий вектор класса\n","\n","  xSamples = np.array(xSamples)\n","  ySamples = np.array(ySamples)\n","\n","  return (xSamples, ySamples)"],"metadata":{"id":"ovkRq0whY40o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ЭТИ ПАРАМЕТРЫ МОЖНО И НУЖНО МЕНЯТЬ\n","# Задаём базовые параметры\n","xLen = 50 # Размер окна (количество слов в векторе)\n","step = 6 # Шаг разбиения текста на векторы"],"metadata":{"id":"UvgAipZ7fa0I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xTrainId, yTrain = createSetsMultiClasses(trainWordIndexes, xLen, step)\n","xTestId, yTest = createSetsMultiClasses(testWordIndexes, xLen, xLen)\n","\n","# для каждого \"окна\" класса мы в соответствие ставим значение true или false => поэтому длины x и y одинаковые\n","print(\"Размерности тренировочного набора\")\n","print(xTrainId.shape)\n","print(yTrain.shape)\n","print()\n","print(\"Размерности тестового набора\")\n","print(xTestId.shape)\n","print(yTest.shape)"],"metadata":{"id":"Q6ApnH26fcNg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(xTrainId[0])"],"metadata":{"id":"47lRIem-fuph"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Для модели BOW - преобразовываем в Bag Of Words\n","xTrain = tokenizer.sequences_to_matrix(xTrainId.tolist())\n","xTest  = tokenizer.sequences_to_matrix(xTestId.tolist())\n","\n","# Для остальных моделей - НЕ преобразовываем в Bag Of Words\n","\n","# xTrain = xTrainId\n","# xTest = xTestId\n","\n","print(\"Размерность обучайющей выборки\")\n","print(xTrain.shape)\n","print(xTrain[0][0:100]) # Фрагмент набора слов в виде Bag of Words\n","\n","print()\n","\n","print(\"Размерность тестовой выборки\")\n","print(xTest.shape)\n","print(xTest[0][0:100]) # Фрагмент набора слов в виде Bag of Words"],"metadata":{"id":"YHFyIhAHf2I3"},"execution_count":null,"outputs":[]}]}