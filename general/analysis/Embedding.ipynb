{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64t_8Ex5Ee2e"
      },
      "source": [
        "# Классификация произведений писателей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "e8O4-nPxEUqJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np # Для работы с данными \n",
        "import matplotlib.pyplot as plt # Для вывода графиков\n",
        "import os # Для работы с файлами\n",
        "from config import Config\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.keras import utils # Для работы с категориальными данными\n",
        "from tensorflow.keras.models import Sequential # Полносвязная модель\n",
        "from tensorflow.keras.layers import Dense, Dropout, SpatialDropout1D, BatchNormalization, Flatten, Activation, Embedding # Слои для сети\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer # Методы для работы с текстами\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # Метод для работы с последователь"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "P8W-qFO2MRY9"
      },
      "outputs": [],
      "source": [
        "# Загрузка данных файлов в списки \n",
        "trainWordIndexes = np.load(Config.TRAIN_WORD_INDEXES_FILENAME, allow_pickle=True)\n",
        "testWordIndexes = np.load(Config.TEST_WORD_INDEXES_FILENAME, allow_pickle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8NaD-WcNwvF"
      },
      "source": [
        "Создаем xTrain и yTrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "dWRb5y5MNpR4"
      },
      "outputs": [],
      "source": [
        "# Формирование обучающей выборки по листу индексов слов\n",
        "# путем разделения на короткие векторы\n",
        "# wordIndexes - массив индексов\n",
        "# xLen - размер окна\n",
        "# step - шаг окна\n",
        "def getSetFromIndexes(wordIndexes, xLen, step):\n",
        "  xText = []\n",
        "  wordsLen = len(wordIndexes) # Считаем количество слов\n",
        "  index = 0 # Задаем начальный индекс \n",
        "\n",
        "  while (index + xLen <= wordsLen): # Идём по всей длине вектора индексов\n",
        "    xText.append(wordIndexes[index:index+xLen]) # \"Откусываем\" векторы длины xLen\n",
        "    index += step # Смещаеммся вперёд на step\n",
        "    \n",
        "  return xText\n",
        "\n",
        "\n",
        "# Формирование обучающей и проверочной выборки для каждого класса\n",
        "# wordIndexes - массив индексов\n",
        "# xLen - размер окна\n",
        "# step - шаг окна\n",
        "def createSetsMultiClasses(wordIndexes, xLen, step): # Функция принимает последовательность индексов, размер окна, шаг окна\n",
        "  nClasses = len(wordIndexes) # Количество классов\n",
        "  classesXSamples = []        # Здесь будет список размером \"кол-во классов*кол-во окон в тексте*длину окна (например, 6 по 1341*1000)\"\n",
        "  for wI in wordIndexes:      # Для каждого текста выборки из последовательности индексов\n",
        "    classesXSamples.append(getSetFromIndexes(wI, xLen, step))\n",
        "\n",
        "  # Формируем один общий xSamples\n",
        "  xSamples = []\n",
        "  ySamples = []\n",
        "  \n",
        "  for t in range(nClasses):\n",
        "    xT = classesXSamples[t]\n",
        "    for i in range(len(xT)): # Перебираем каждое окно определенного класса\n",
        "      xSamples.append(xT[i]) # Добавляем в общий список выборки\n",
        "      ySamples.append(utils.to_categorical(t, nClasses)) # Добавляем соответствующий вектор класса\n",
        "\n",
        "  xSamples = np.array(xSamples)\n",
        "  ySamples = np.array(ySamples)\n",
        "\n",
        "  \n",
        "  return (xSamples, ySamples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "nXWfO0zNO88J"
      },
      "outputs": [],
      "source": [
        "# Задаём базовые параметры\n",
        "xLen = 500 # Размер окна (количество слов в векторе)\n",
        "step = 60 # Шаг разбиения текста на векторы\n",
        "numWords = 4357"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuczpcnjPAS2",
        "outputId": "7e389247-1e13-4379-d1c4-0b3e4988179c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Размерности тренировочного набора\n",
            "(6721, 500)\n",
            "(6721, 2)\n",
            "\n",
            "Размерности тестового набора\n",
            "(86, 500)\n",
            "(86, 2)\n"
          ]
        }
      ],
      "source": [
        "# Формируем обучающую и тестовую выборку\n",
        "xTrain, yTrain = createSetsMultiClasses(trainWordIndexes, xLen, step)\n",
        "xTest, yTest = createSetsMultiClasses(testWordIndexes, xLen, xLen)\n",
        "print(\"Размерности тренировочного набора\")\n",
        "print(xTrain.shape)\n",
        "print(yTrain.shape)\n",
        "print()\n",
        "print(\"Размерности тестового набора\")\n",
        "print(xTest.shape)\n",
        "print(yTest.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndL5g2EyPqy7",
        "outputId": "25e6ac0b-c113-4497-96a6-ae779a8d5c77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 5748    69   652    16  8497  1554   223   249   381  3499     3  6461\n",
            "    30   124   255   303   336 16379     2   313   233  2400  1258   120\n",
            "    29   391    14     1    45 12534  4694     2  1324  8498    27  3733\n",
            "   846   298 16380 12535 16381   820    85   194   164  5168     2 16382\n",
            "  7346    66  2500     1   405 10161     3     2   232     1    27     1\n",
            "  5749 16383     1   280  1713   187  2911    44  1605     7    49  3084\n",
            "    27     2 16384 16385   298    62    23   129     1    51  1291     1\n",
            "  6461    22   406  8499  2615    29  1853     5    86   614  4015     4\n",
            "   124 10162    45  2291     4  1782    19  1478    27   138    21  2093\n",
            "  1186  5169   626   588   774  1854     1  8500     3   240 10163  3085\n",
            "  3499   250   271    29   156     5   774   501  6462  8501  6463  1029\n",
            "     2  5170    16   697   239    21  4695     3    13     6   447   711\n",
            "    29    19    34   517     2    91   293 10164  6464     9  1187 16386\n",
            "     3  1119  1783    45    19    34  1855    42  3303     2 16387    26\n",
            " 10162    59     1  1652   615     2 10165  1187 16386 16388   653     6\n",
            "    14  7346     6    14   712    23   109    11  1606   304    11  5750\n",
            "     2    92 12536 12537  1929     1  3304     1 16389    57    29  1853\n",
            "     5   698   124     1   205 10166    54     9    12   860   135     1\n",
            "  1394  8502    76    57     2    74  7346    10  1119  1783 16388   653\n",
            "  6465     1   871     4   871     1    17    18   328    75   124 10167\n",
            " 12537 10162     2  3500    21  1784     1   114   453  2501  1929 16390\n",
            "  5171 10168     2  7347     3  8503 10169   250   271    29   156     5\n",
            "    35   652     2 10165 10170     2   168 12538   135     3  4327   124\n",
            " 10171   226  1394    19   124  5751  5752     1    22  5753  3734    82\n",
            "    26 10162    59  1093     1   558   422  1030   197   286   951   261\n",
            "     5   774   123   654 16391   899    16  5172     3  7348  1714    11\n",
            "  4016    58   103 10171   287    75     1  1148    27   222     5  6466\n",
            "  7349    15    62  7350    62   427   746     4 12539    63   400     5\n",
            "     3  7351    12     4  2183    86    98   872     1     1    13  1555\n",
            "  3501  4696    69   652   187     6   990  1785     3  1479     2   699\n",
            "     1   153   381    76    37   747   256     7   409     3   316     5\n",
            "   774   358     6 10172  8497   249     1     1     3     9    36  3305\n",
            "     4  1782  3502    25   494    12  1259  3306  1395   518   214    50\n",
            "   333   711  2616  5173 12540    85 10173  1031   168  1607    36     8\n",
            " 16392  6467  1856  4328     7   616  5174 10161     3  7352   547 12541\n",
            "   559    17    49   627     6 12542    49  5175  8504     5     2    23\n",
            "   152  1396  6468  2184  1607  2616  5173  1786  8505  1397   748   664\n",
            "  6469 16393  6470     3 10174    14  2912    36    66   319  1149    71\n",
            "  3307  2616   588 16394    27 12543     8 12544     2  1787 16392   164\n",
            "    49  1929  6471  5176 16395     4   969     1    15    20  2401    49\n",
            "   205  3308  3735 12540    27  1291 16396    18   735  4697     3 16385\n",
            "   103     1   548   198   597   164    19  8506]\n"
          ]
        }
      ],
      "source": [
        "print(xTrain[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVDds6jKQGqs",
        "outputId": "3ccec199-8c46-4bd5-a8ed-c8ea3238cd71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Размерность обучайющей выборки\n",
            "(6721, 500)\n",
            "(6721, 2)\n",
            "\n",
            "Размерность тестовой выборки\n",
            "(86, 500)\n",
            "(86, 2)\n"
          ]
        }
      ],
      "source": [
        "print(\"Размерность обучайющей выборки\")\n",
        "print(xTrain.shape)\n",
        "print(yTrain.shape)\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Размерность тестовой выборки\")\n",
        "print(xTest.shape)\n",
        "print(yTest.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKEckmaZQnkJ"
      },
      "source": [
        "Нейросеть для классификации текстов на базе Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5jTU1JvQjzh",
        "outputId": "0cb837d2-38ee-4456-9c46-23f603afe66a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 500, 10)           43570     \n",
            "                                                                 \n",
            " spatial_dropout1d_2 (Spatia  (None, 500, 10)          0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 5000)              0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 5000)             20000     \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 10002     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 73,572\n",
            "Trainable params: 63,572\n",
            "Non-trainable params: 10,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Создаём полносвязную сеть\n",
        "model = Sequential()\n",
        "model.add(Embedding(numWords, 10, input_length=xLen))\n",
        "model.add(SpatialDropout1D(0.20))\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kw0fZMnGQ3TE",
        "outputId": "f38c86a5-ca8b-4d69-dfa6-38cfaf44f6ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "ename": "InvalidArgumentError",
          "evalue": " indices[8,23] = 9352 is not in [0, 4357)\n\t [[node sequential_3/embedding_2/embedding_lookup\n (defined at C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\layers\\embeddings.py:191)\n]] [Op:__inference_train_function_2833]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_3/embedding_2/embedding_lookup:\nIn[0] sequential_3/embedding_2/embedding_lookup/2506:\t\nIn[1] sequential_3/embedding_2/Cast (defined at C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\layers\\embeddings.py:190)\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Program Files\\Python38\\lib\\runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Program Files\\Python38\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Program Files\\Python38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Program Files\\Python38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Program Files\\Python38\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Local\\Temp/ipykernel_1136/1127991030.py\", line 2, in <module>\n>>>     history = model.fit(xTrain,\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n>>>     y_pred = self(x, training=True)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\sequential.py\", line 373, in call\n>>>     return super(Sequential, self).call(inputs, training=training, mask=mask)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n>>>     return self._run_internal_graph(\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n>>>     outputs = node.layer(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\layers\\embeddings.py\", line 191, in call\n>>>     out = tf.nn.embedding_lookup(self.embeddings, inputs)\n>>> ",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1136/1127991030.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Обучаем сеть\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m history = model.fit(xTrain, \n\u001b[0m\u001b[0;32m      3\u001b[0m                     \u001b[0myTrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mInvalidArgumentError\u001b[0m:  indices[8,23] = 9352 is not in [0, 4357)\n\t [[node sequential_3/embedding_2/embedding_lookup\n (defined at C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\layers\\embeddings.py:191)\n]] [Op:__inference_train_function_2833]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_3/embedding_2/embedding_lookup:\nIn[0] sequential_3/embedding_2/embedding_lookup/2506:\t\nIn[1] sequential_3/embedding_2/Cast (defined at C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\layers\\embeddings.py:190)\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Program Files\\Python38\\lib\\runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Program Files\\Python38\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Program Files\\Python38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Program Files\\Python38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Program Files\\Python38\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Local\\Temp/ipykernel_1136/1127991030.py\", line 2, in <module>\n>>>     history = model.fit(xTrain,\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n>>>     y_pred = self(x, training=True)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\sequential.py\", line 373, in call\n>>>     return super(Sequential, self).call(inputs, training=training, mask=mask)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n>>>     return self._run_internal_graph(\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n>>>     outputs = node.layer(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\alexa\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\layers\\embeddings.py\", line 191, in call\n>>>     out = tf.nn.embedding_lookup(self.embeddings, inputs)\n>>> "
          ]
        }
      ],
      "source": [
        "# Обучаем сеть\n",
        "history = model.fit(xTrain, \n",
        "                    yTrain, \n",
        "                    epochs=20,\n",
        "                    batch_size=64,\n",
        "                    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "H3Sakk0YQ7j4",
        "outputId": "f1b3bc58-8aec-4db4-f22f-d4c9cd4f7d1e"
      },
      "outputs": [],
      "source": [
        "# Результаты обучения\n",
        "plt.plot(history.history['accuracy'], \n",
        "         label='Доля верных ответов на обучающем наборе')\n",
        "plt.plot(history.history['val_accuracy'], \n",
        "         label='Доля верных ответов на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('Доля верных ответов')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jgZwyDwRTVN"
      },
      "source": [
        "Проверяем работу обученной нейросети"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4Nip_hUS1T9",
        "outputId": "8087c578-100f-4156-d78c-6cd678a8239c"
      },
      "outputs": [],
      "source": [
        "# Проверяем точность на тестовой выборке\n",
        "\n",
        "rightAnswer = [0,0,0,0,0,0]\n",
        "totalAnswer = [0,0,0,0,0,0]\n",
        "\n",
        "# Получаем результаты распознавания для каждого класса\n",
        "currPred = model.predict(xTest)\n",
        "# Определяем номер распознанного класса для каждохо вектора\n",
        "currOut = np.argmax(currPred, axis=1)\n",
        "# Определяем правильный класс для каждохо вектора\n",
        "yOut = np.argmax(yTest, axis=1)\n",
        "\n",
        "print(currPred.shape)\n",
        "print(currOut.shape)\n",
        "print(yOut.shape)\n",
        "print()\n",
        "\n",
        "\n",
        "# Считаем сколько ответов всего и сколько из них правильных\n",
        "for i in range(len(yOut)):\n",
        "  predictA = currOut[i]\n",
        "  rightA   = yOut[i]\n",
        "\n",
        "  totalAnswer[rightA] += 1\n",
        "  if predictA == rightA:\n",
        "    rightAnswer[rightA] += 1\n",
        "\n",
        "# Подсчитываем точность классификации\n",
        "print(\"Точность распознавания текстов писателей\")\n",
        "for i in range(labelsNum):\n",
        "  print(\"{:12s}: {:3d} из {:3d} - {:3.2f}%\".format(labels[i], rightAnswer[i], totalAnswer[i], (rightAnswer[i]/totalAnswer[i]*100)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Копия блокнота \"IThub - ML - 10 - Embedding\"",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
