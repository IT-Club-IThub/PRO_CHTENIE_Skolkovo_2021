{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')\n",
    "from config import Config\n",
    "\n",
    "import json\n",
    "import numpy as np # Для работы с данными \n",
    "import sys\n",
    "import os\n",
    "\n",
    "from tensorflow.keras import utils # Для работы с категориальными данными\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer # Методы для работы с текстами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_DATA_DIR = '../../Satellites'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаём два списка, в пустые элементы которых будем добавлять тексты\n",
    "# в первом элементе будет храниться текст с ответом False, во втором - True\n",
    "textClasses = ['', '']\n",
    "\n",
    "\n",
    "# открываем файл с id эссе и ответами\n",
    "with open(JSON_DATA_DIR + '/train/train_standart.json', 'r') as f_list:\n",
    "  data = json.load(f_list)\n",
    "\n",
    "  # проходимся по каждому \"блоку\" с эссе\n",
    "  for i in range(len(data)):\n",
    "    elem = data[i]\n",
    "\n",
    "    with open(JSON_DATA_DIR + f'/train/essays/{elem[\"id\"]}.json', 'r') as essay:\n",
    "      file = json.load(essay)\n",
    "      text = file['text']\n",
    "      if elem['answer'] == False:\n",
    "        textClasses[0] += text\n",
    "        textClasses[0] += '#'\n",
    "      else:\n",
    "        textClasses[1] += text\n",
    "        textClasses[1] += '#'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаём два списка, в пустые элементы которых будем добавлять тексты\n",
    "# в первом элементе будет храниться текст с ответом False, во втором - True\n",
    "texts = []\n",
    "\n",
    "# открываем файл с id эссе и ответами\n",
    "with open(JSON_DATA_DIR + '/test/test_task.json', 'r') as f_list:\n",
    "  data = json.load(f_list)\n",
    "\n",
    "  # проходимся по каждому \"блоку\" с эссе\n",
    "  for i in range(len(data)):\n",
    "    elem = data[i]\n",
    "\n",
    "    with open(JSON_DATA_DIR + f'/test/essays/{elem[\"id\"]}.json', 'r') as essay:\n",
    "      file = json.load(essay)\n",
    "      text = file['text']\n",
    "      texts.append([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_false = textClasses[0].split(\"#\")\n",
    "texts_true = textClasses[1].split(\"#\")\n",
    "\n",
    "trainText = []\n",
    "trainText.append(' '.join(texts_false))\n",
    "trainText.append(' '.join(texts_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(\n",
    "    filters='!\"#$%&()*+,-–—./…:;<=>?@[\\\\]^_`{|}~«»\\t\\n\\xa0\\ufeff',\n",
    "    lower=True,\n",
    "    split=' ',\n",
    "    oov_token='unknown',\n",
    "    char_level=False)\n",
    "\n",
    "tokenizer.fit_on_texts(trainText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSetFromIndexes(wordIndexes, xLen, step):\n",
    "  xText = []\n",
    "  wordsLen = len(wordIndexes) # Считаем количество слов\n",
    "  index = 0 # Задаем начальный индекс \n",
    "\n",
    "  while (index + xLen <= wordsLen): # Идём по всей длине вектора индексов\n",
    "    xText.append(wordIndexes[index:index+xLen]) # \"Откусываем\" векторы длины xLen\n",
    "    index += step # Смещаемся вперёд на step\n",
    "    \n",
    "  return xText\n",
    "\n",
    "def createSetsMultiClassesTest(wordIndexes, xLen, step): # Функция принимает последовательность индексов, размер окна, шаг окна\n",
    "  nClasses = len(wordIndexes) # Количество классов\n",
    "  classesXSamples = []        # Здесь будет список размером \"кол-во классов*кол-во окон в тексте*длину окна\"\n",
    "  for wI in wordIndexes:      # Для каждого текста выборки из последовательности индексов\n",
    "    classesXSamples.append(getSetFromIndexes(wordIndexes[0], xLen, step))\n",
    "\n",
    "  # Формируем один общий xSamples\n",
    "  xSamples = []\n",
    "  ySamples = []\n",
    "  \n",
    "  for t in range(nClasses):\n",
    "    xT = classesXSamples[t]\n",
    "    for i in range(len(xT)): # Перебираем каждое окно определенного класса\n",
    "      xSamples.append(xT[i]) # Добавляем в общий список выборки\n",
    "      ySamples.append(utils.to_categorical(t, nClasses)) # Добавляем соответствующий вектор класса\n",
    "\n",
    "  xSamples = np.array(xSamples)\n",
    "  ySamples = np.array(ySamples)\n",
    "\n",
    "  return (xSamples, ySamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "xLen = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays = []\n",
    "yTest = []\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    testTextArray = tokenizer.texts_to_sequences(texts[i][0])\n",
    "    xTestId, _ = createSetsMultiClassesTest(testTextArray, xLen, xLen)\n",
    "    essays.append(xTestId)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\42E9~1\\AppData\\Local\\Temp/ipykernel_34448/74609616.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxTestId\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "print(xTestId[0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17331542a1b186c80143aaa34f2da524bc3765ccabf78956ee6995701fe0dc3f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
